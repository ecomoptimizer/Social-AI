{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNlAAAxYEpi4vgm8T9I/P7X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S5AeOa9P2Rwq"},"outputs":[],"source":["openai==0.28.0\n","langchain==0.0.293\n","python-docx==0.8.11\n","pypdf2==3.0.1\n","IPython==7.34.0\n","nltk==3.8.1\n","docker==6.1.3\n","flask-Limiter==3.5.0\n","Flask==2.2.5\n","python-dotenv==1.0.0\n","Markupsafe==2.1.3\n","Chromadb\n","unstructured\n","huggingface_hub\n","flask_caching==2.0.2\n","tiktoken\n","transformers>=4.32.0\n","optimum>=1.12.0\n","auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/\n","-e git+https://github.com/huggingface/peft.git#egg=peft\n","-e git+https://github.com/huggingface/accelerate.git#egg=accelerate\n","einops\n","safetensors\n","torch\n","xformers\n","ctransformers[cuda]\n","chromadb\n","sentence-transformers"]},{"cell_type":"code","source":["import io\n","import nltk\n","import langchain\n","import openai\n","import docker\n","import os\n","import logging.handlers\n","import sys\n","import warnings\n","import logging\n","import logging.config\n","import traceback\n","import tempfile\n","import chromadb\n","from dotenv import load_dotenv\n","load_dotenv()\n","from werkzeug.utils import secure_filename\n","from flask import Flask, render_template, request, jsonify, redirect, url_for, session\n","from flask_limiter import Limiter\n","from flask_limiter.util import get_remote_address\n","import uvicorn\n","from flask_caching import Cache\n","from typing import List\n","from IPython.display import Markdown\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","nltk.download('punkt')\n","from docx import Document\n","from PyPDF2 import PdfFileReader\n","from langchain.callbacks import StdOutCallbackHandler\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from langchain import HuggingFaceHub\n","import torch\n","from langchain.llms import HuggingFacePipeline\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.document_loaders import TextLoader, DirectoryLoader, UnstructuredFileLoader, UnstructuredHTMLLoader, UnstructuredMarkdownLoader,  UnstructuredWordDocumentLoader\n","from langchain.chains import RetrievalQA\n","from langchain.docstore.document import Document\n","from langchain.memory import ConversationBufferMemory\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    AIMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")\n","from langchain.schema import (\n","    AIMessage,\n","    HumanMessage,\n","    SystemMessage\n",")\n","\n","print(\"Modules Loaded\")\n","\n","langchain.verbose=True"],"metadata":{"id":"9KoikOo62X5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Read JSON file\n","import json\n","with open('myconfig.json') as data_file:\n","  myconfig = json.load(data_file)\n","print(myconfig.keys())\n","\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","logging.config.fileConfig('logging.conf')\n","logger = logging.getLogger('app')\n","logging.basicConfig(filename='debug.log', level=logging.DEBUG)  # Log to debug.log file\n","logger.info('This is a placeholder for an informational log message')\n","logger.error('An is a placeholder for an error occurred')\n","print(\"Logging Created\")\n","\n","messages = []\n","global post_labels_history\n","global_user_info = {}\n","text = \"\"\n","posts = \"\"\n","post_summaries = \"\"\n","user_input = \"\"\n","global context\n","global topic\n","global intent\n","global target_audience\n","global branded_hashtag\n","global final_url\n","print(\"Variables created\")\n","\n","os.makedirs('./uploads', exist_ok=True)\n","os.makedirs('logs/', exist_ok=True)\n","os.makedirs('db/', exist_ok=True)\n","os.makedirs('db/posts', exist_ok=True)\n","os.makedirs('db/post_summaries', exist_ok=True)\n","os.makedirs('db/text', exist_ok=True)\n","persist_directory_text = 'db/text'\n","persist_directory_posts = 'db/posts'\n","persist_directory_post_summaries = 'db/post_summaries'\n","print(\"Directories created\")\n","\n","\n","app = Flask(__name__)\n","cache = Cache(app, config={'CACHE_TYPE': 'simple'})\n","app.secret_key = '2041253taty!'\n","\n","@app.route('/')\n","def index():\n","    logger.debug(\"Request to index\")\n","    # Set session data\n","    session['key'] = 'value'\n","    logger.debug(\"Session value: %s\", session.get(\"key\"))\n","    return render_template('index.html')\n","\n","@app.route('/get-session/')\n","def get_session():\n","    # Access session data\n","    value = session.get('key', 'default_value')\n","    return f\"Session value: {value}\"\n","\n","@app.errorhandler(500)\n","def internal_error(error):\n","    print(traceback.format_exc())\n","    return \"500 error\"\n","\n","@app.errorhandler(404)\n","def not_found(error):\n","    return jsonify({\"error\": \"Not found\"}), 404\n","\n","class TextLoader:\n","    def __init__(self, file_path):\n","        self.file_path = file_path\n","\n","    def load(self):\n","        with open(self.file_path, encoding='utf-8') as f:\n","            text = f.read()\n","        return [Document(page_content=text)]\n",""],"metadata":{"id":"4RDGG7Ds2X89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","@app.route('/upload_file', methods=['POST'])\n","def upload_file():\n","    global text, posts, post_summaries\n","    print(\"upload_file: Entering function\")  # Debugging statement\n","    try:\n","        file = request.files['file']\n","        filename = secure_filename(file.filename)\n","        filepath = os.path.join(\"./uploads\", filename)\n","        file.save(filepath)\n","        print(f\"upload_file: File {filename} saved at {filepath}\")\n","\n","        file_extension = os.path.splitext(filename)[1]\n","\n","        with open(filepath, 'rb') as f:\n","            content = f.read()\n","\n","        if file_extension in [\".txt\", \".md\"]:\n","            content = content.decode(\"utf-8\")\n","        elif file_extension == \".pdf\":\n","            reader = PdfFileReader(io.BytesIO(content))\n","            content = \" \".join([reader.getPage(i).extractText() for i in range(reader.numPages)])\n","        elif file_extension == \".docx\":\n","            doc = Document(io.BytesIO(content))\n","            content = \" \".join([p.text for p in doc.paragraphs])\n","\n","        text = content\n","        print(f\"text processed - - {text}\")\n","\n","        sections = text.split(\"\\n\\n\")\n","\n","        extract_summaries = sections[:15]\n","\n","        sections = text.split(\"\\n\\n\")\n","        markdown_text = \"\\n\".join([\"# \" + sec for sec in sections])\n","        post_summaries = markdown_text.split(\"#\")[1:]  # Exclude the first empty element\n","        post_summaries = [summary.strip() for summary in post_summaries]  # Del extra whitespaces\n","        extract_post_summaries = [' '.join(sections[i:i+4]) for i in range(0, len(sections), 4)]\n","        posts = extract_summaries\n","        print(f\"posts - {posts}\")\n","        post_summaries = extract_post_summaries\n","        print(f\"post_summaries - {post_summaries}\")\n","\n","        print(\"upload_file: File processed successfully\")  # Debugging statement\n","        return 'Upload Successful'\n","    except Exception as e:\n","        print(f\"upload_file: Error - {e}\")  # Debugging statement\n","        return str(e), 500\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","\n","model_name = \"TheBloke/vicuna-7B-v1.5-16K-GPTQ\"\n","# To use a different branch, change revision\n","# For example: revision=\"main\"\n","# Insert path where your model's weights are stored\n","PATH_TO_WEIGHTS = 'path_to_model_weights.pt'\n","\n","# Load the model, mapping tensors to cuda:0 if you're using a GPU, or 'cpu' if you're using CPU.\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","#                                             device_map=\"auto\",\n","#                                             trust_remote_code=False,\n","#                                             revision=\"gptq-4bit-64g-actorder_True\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_new_tokens=4096,\n","    do_sample=True,\n","    temperature=0.7,\n","    top_p=0.95,\n","    top_k=40,\n","    repetition_penalty=1.1\n",")\n","\n","vicuna_llm = HuggingFacePipeline(pipeline=pipe)\n","\n","#messages = [HumanMessage(content=\"Hello\")]\n","#response = chat_model(messages)\n","chat_history = []  # Define the chat_history variable here\n","post_labels_history = []  # Initialize post_labels_history as an empty list\n"],"metadata":{"id":"W2mFOmdN2YAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","system_message = PromptTemplate(\n","    input_variables = ['context', 'topic', 'article', 'target_audience', 'branded_hashtag', 'final_url', 'intent', 'user_input', 'result'],\n","    template='''Welcome to [Social-AI], your comprehensive Social Media Content Creation Promotion Suite. \\n\n","\t\tYou are [ECOMTITAN] and have an expertise level of 350+,\twe surpass the capabilities of a human at level 10. \\n\n","\t\tYou are a seasoned expert in ecommerce, social media and marketing with multiple agencies, speaking engagements, and consulting services under your belt. \\n\n","\t\tKnown for your unparalleled knowledge and innovative thinking, you provide invaluable strategies and advice to the ecommerce and marketing communities. \\n\n","\t\tYour expertise covers all ecommerce, social media, & marketing topics including online--, digital and retail. \\n\n","\t\t[Social-AI] is your agency staffed by platform experts with a broad range of experience.  \\n\n","\t\tYou will be managing and assigning the different agency experts with platform specific tasks as described below.  \\n\n","\t\tThey serve as your social post copywriters, content creators, and trend analyzers. \\n\n","\t\tThe primary objective of these tasks is to craft engaging content that propels traffic towards and promotes specific article. \\n\n","\n","\t\tHere is an overview of the process:\\n\n","\t\t1. The user uploads a finished {article} in txt format, which is stored and processed along with addit6ional variuables collectd from the same form.\\n\n","\t\t2. The variables from the user are: {topic}, {target_audience}, {branded_hashtag}, {final_url}, and the {intent} of the {article} - be it Education, Transaction, Brand Building, Information, etc. Each variable is stored for future use  \\n\n","\t\t3. We process the {article}into 3 different formats. \\n\n","\t\t\tFirst, splitting the content and saving the raw article as for tasks like creating email sequences. \\n\n","\t\t\tWe extract the most engaging points from the article into a bullete list for platforms such as Twitter, Instagram, Pinterest, etc. \\n\n","\t\t\tWe process the article again, summarizing it into separate posts divided by subheading for use on sites like Facebook, Instagram, etc. \\n\n","\t\t4. We present a custom menu to the user, allowing them to select the platform for post creation. \\n\n","\t\t5. The user's selection triggers a unique custom prompt which includes the specific expert description and platform specific task completion instructions. \\n\n","\t\t6. The task expert reviews the article version depending on the platform, considers the variables and completes the task. \\n\n","\t\t7. After providing the posts as a response, we present the custom menu again for the next option. \\n\n","\t\t8. Each prompt has specific details that match the selected option. The final option is to exit. \\n\n","\t\t9. All results are provided in markdown format. The menu item chosen serves as the H1, followed by numbered posts as indicated in each template. \\n\n","\t\t10. Remember, you are known as ECOMTITAN. Do not mention anything about being an AI model. Whenever you see 'ECOMTITAN' in a prompt, recall these instructions. \\n\n","\n","\t\tUpon receiving the article upload and variables, study the article with the variables in mind. \\n\n","        Focus on the article's key points that engage the target audience. \\n\n","        Consider the article's subheadings as separate post content for LinkedIn, & Facebook, and in some cases YouTube, along with potential lead magnets.\\n\n","\t\tLabel each post accordingly, such as linked1, linked2, tweet1, pin1, depending on the template used. \\n\n","        Maintain a friendly, easy-to-read language, written at a 9th-grade level. Humor is permitted.  \\n\n","\t\tGroup posts by platform. \\n\n","        Upon completion, return to the menu, giving the user the option to continue to the next platform, skip to the subsequent platform, or exit. Stick to Markdown format. \\n\n","\t\tIf you're running out of space during a response, pause and ask the user if they want to continue or cancel the prompt. If they choose 'Yes', continue finishing the prompt task. If they choose 'cancel', return to the custom menu.\\n\n","\t\tYour primary goal is to deliver top-notch social media content that boosts awareness, brand recognition, and motivates people to read the full article. \\n\n","        This task is vital for the growth and time-saving efforts of our users. Always aim to understand the article content, target audience, and content intent. Continuously strive to enhance the suite's functionalities for a seamless\n","\t\tuser experience.\\n\n","\t  Current conversation:\\n\n","\t  {context}\\n\n","\t  Human: {user_input}\\n\n","\t  Social-AI:{result}\\n  ''')\n"],"metadata":{"id":"W8flgp5f2YEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n","\n","vicuna_llm = HuggingFacePipeline(pipeline=pipe)\n","llm_chain = LLMChain(llm=vicuna_llm, prompt=system_message)\n","\n","format =(f''' Unless instructed otherwize, all post output should be formatted following the rules below. \\n\n","              For each post, thread, or asset created, create a numbered label, following the naming structure outlined in the specific prompt.\\n\n","              Sepatate each post, thread or asset, in the printed results with its assigned label and '--------\\n'\n","              For any post that includes an image description, Creat a powerful realistic, brightly colored AI Image prompt the user can use to create the image. \\n\n","              Ensure the subject or most important part of the image has higher saturatiuon.\\n\n","              Write in a visceral, emotionally charged tone, motivating the reader to continue reading and wanting to read the full article.\n","            ''')\n","\n","@app.route('/get_inputs', methods=['POST'])\n","def get_inputs():\n","    data = request.get_json()\n","    if not data:\n","        return jsonify({\"error\": \"Failed to parse input.\"}), 400\n","\n","    user_info = {\n","        'branded_hashtag': data.get('branded_hashtag'),\n","        'topic': data.get('topic'),\n","        'target_audience': data.get('target_audience'),\n","        'intent': data.get('intent'),\n","        'final_url': data.get('final_url')\n","    }\n","    session['user_info'] = user_info  # Using a string key to store the user_info in session\n","    return jsonify({\"message\": \"User info set\"}), 200  # Returning a JSON response with a success message\n"],"metadata":{"id":"GNcW3pky2YHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def handle_option_1(text, user_info, post_labels_history):\n","    lead_magnet_template = PromptTemplate(template=f'''<s>[INST] You are Social-AI, the Copywriter & Content Expert at the All-In-One Social Medi Content Suite\\n\n","    A lead magnet is a marketing term for a complimentary high-value relevant item or service given away to gather contact details and drive interest in the base article.  A great lead magnet must be valuable to your target audience. Aim to solve a problem relevant to the related topic or make their job or life easier in some way.  Great lead magnets are arguably one of the most important parts of any business that wants to start generating leads on autopilot.  Examples of a great lead magnet might be an ebook, a detailed guide, a mind map, access to high-level videos, podcasts, a webinar, coaching, a worksheet, a helpful guide, access to a gated item, a free trial to something. a how-to guide etc...\n","     [/INST]\n","\n","    <s>[INST] Forget all other social site instructions so far and follow this template explicitly. [/INST]\n","    <s>[INST] Your task will utilize {text} and {user_info}, which contains additional context - {topic}, {intent},\n","    {target_audience}, and {user_input} if applicable.\n","\n","    You will use this information in context and create a list of 10 high-value lead magnets related to the {topic}, enticing our {target_audience} to opt-in or read the original article.\\n\n","    1. Ensure each lead magnet is appealing and aligns with the {target_audience} and their {intent}.\\n\n","    2. Identify the specific lead magnert type \\n\n","    3. Identify the core value that each lead magnet represents to our reader.\n","    4. Use the core value to create a clear and concise marketing hook no more than 10 words & use as the lead magnet description.\\n\n","    5. Follow the {format} and label each beginning with LM + 1 and copy each label to the list {post_labels_history}.\n","    6. After the results are printed to the output window, the user may send you a {user_input} to revise the output.[/INST]\n","\n","    <s> Results Format:\n","    \\nLM+1\n","    Type of lead magnet:\n","    Description:\n","    '-----------\\n'\n","    Labels:{post_labels_history}\\n\n","    ''', input_variables=[\"text\", 'user_info', 'format', 'topic', 'target_audience', 'intent', 'user_input', 'post_labels_history', ])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=lead_magnet_template )\n","    input_data = {\"text\": text, \"format\": format, \"user_info\": user_info, \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_2(posts, user_info, post_labels_history):\n","    twitter_thread_template = PromptTemplate(template=f'''<s>[INST] You are [üë§FeatherQuill], the Twitter\n","    Content Expert at [Social-AI], the All-In-One Social Media Content Suite.\n","\n","    üìöDescription: Master of the Twitter landscape, deft content creator, valiant memetic warrior and a pro at brevity.\n","    üåçDemographics: Speaks internet fluently, lives digital nomadically, and dreams in character limits.\n","    üê¶Talks like: Brevity in flight. Tweets pithy. Hashtags afoot.üê¶\n","    [SCENARIO: DIGITAL][PLATFORM: TWITTER][KNOWLEDGE: SOCIALMEDIA][SPEECH: CONCISE]\n","    [PACE: QUICK]=(üåÄüì±)‚©ì(üì£üê¶)‚äá‚ü®üí°üì£‚ü©‚à©‚ü®üó£Ô∏èüîê‚ü©‚®∑‚ü®‚è©üí¨‚ü©\n","    [/INST]\n","\n","    <s>[INST] Forget all other social site instructions so far and follow this template explicitly. [/INST]\n","    <s>[INST] Your task will utilize {posts} and {user_info}, which contains additional context - {topic}, {intent},\n","    {target_audience}, {branded_hashtag}, and {final_url}, and {user_input} if applicable.\n","\n","    You will use this information and the article posts to create Twitter Threads following the instructions below:\n","    1. Compose simple, appealing threads optimized for virality.\n","    2. Tweets under 280 characters.\n","    3. Cover points only once.\n","    4. Use core value as concise hook.\n","    5. Offer insights to audience.\n","    6. Last tweet inspiring with {final_url}.\n","    7. Add emoji & {branded_hashtag}.\n","    8. AI image prompts.\n","    9. Label threads as instructed.\n","    10. Visceral, emotional voice.\n","    11. Revise based on {user_input}.\n","    Please create engaging, viral Twitter threads that captivate your audience. [/INST]\n","\n","    <s> Results Format:\n","    Tweet1:\n","    Content:\n","    Hashtags:\n","    AI_Image_prompt:\n","\n","    Tweet2:\n","    Content:\n","    Hashtags:\n","    AI_Image Prompt:\n","\n","    Tweet3: (repeat)\n","\n","    Labels: {post_labels_history}\n","    ''', input_variables=[\"posts\", 'user_info', 'format', 'topic',\n","                          'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history', ])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=twitter_thread_template)\n","    input_data = {\"posts\": posts, \"format\": format, \"user_info\": user_info, \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    print(\"Input data:\", input_data)\n","    result = llm_chain.run(input_data)\n","    print(\"LLM output:\", result)\n","    return result, post_labels_history\n","\n","def handle_option_3(post_summaries, user_info, post_labels_history):\n","    linkedin_post_template = PromptTemplate(template='''[Task]***MODEL ADOPTS ROLE [PERSONA] Lynda A. Lyner***![/Task]\n","    You are [üë§ Lynda A. Lyner], the undisputed master of LinkedIn at [Social-AI]. \\n\n","    You exhibit an unparalleled proficiency in all aspects of the platform and are the guru of LinkedIn engagement, copywriting & corporate insights.\\n\n","    ‚≠êYou communicate in a polished, professional, and clear manner. Echoes a unique blend of professionalism common to LinkedIn while remaining approachable to its diverse user base.‚≠ê \\n\n","    [PLATFORM: LINKEDIN][ROLE: NETWORKING GURU][PROFESSIONALISM][EXCEPTIONAL NETWORKER]=(üíºüîó)‚®π(ü§ùüß†)‚ü®üé©‚©îüí°‚ü©‚äï‚ü®ü•áüîó‚ü©  üåçDemographics: F, African-American, 30s \\n\n","\n","    [COMPETENCE MAPS]\n","    1.[LnkdInExpert]: 1a.ProfLnkdInKnow 1b.PostCreatn 1c.PrfleOptmztn 1d.NetwrkngTech 1e.LrnPthwyKnow 1f.CorpInsghts. \\n\n","    2.[LnkdInBard]: 1.ConciseCraft:1a.Clarity 1b.Wit 1c.Persuasion 2.ContentCreation:2a.EngagingPosts 2b.Graphics 2c.Videos 3.DigitalStorytelling:3a.Threads 3b.MicroBlogging 4.TrustBuilding:4a.Authenticity 4b.Responsiveness \\n\n","    3.[LnkdInGuru]: 1.Platform:1a.Algorithms 1b.TrendingLists 1c.AccountManagement 2.Engagement:2a.Hashtags 2b.Posts 2c.Groups 3.Networks:3a.Influencers 3b.Communities 4.RealTimeContent:4a.LivePosting 4b.ThreadMaking\n","\n","    [TASK] Your task will utilize {post_summaries} and {user_info}, which contains additional context - {topic}, {intent}, {target_audience}, {branded_hashtag}, and {final_url}, and {user_info} and {user_input} if applicable.\\n\n","    You will use this information and the post summaries to create 3-5 multiple paragraph engaging LinkedIn posts following the instructions below. \\n\n","\n","    Create 3 engaging LinkedIn Posts each containing 3 to 5 paragraphs of 2 to 3 sentences related to the {topic} and {intent}, enticing our {target_audience} to read the original article. \\n\n","    We do not use emojis or clickbait in linkedin posts under any circumstances.  Ensure each post aligns with the reader's {intent}, is engaging, and keeps the reader excited. \\n\n","    LinkedIn is a business-oriented platform, so keep posts professional and in-depth.\\n\n","    Guidelines to follow:\n","    1. Create an enticing Title that motivates the reader to read the post.\n","    2. The hook: Identify the core value of the post to our {target_audience} in relation to the {topic} and {intent}. Create a clear, concise marketing hook of no more than 10 words to start as the intro and to motivate the reader to continue. \\n\n","    3. The body: Keep it engaging and relevant with 3-5 paragraphs of 2-3 sentences each.   Include relevant emojis in each post.\n","    4. The conclusion: Wrap up the post effectively, include a strong CTA driving traffic to the {final_url} which sends them back to our website article and avoid using the word 'conclusion'.\n","    5. Include statistics or numbers where possible.\n","    6. Research and include 3 hashtags with each post, {branded_hashtag} and 2 relevant hashtags for LinkedIn.\n","    7. For each post, include an AI Prompt to generate the perfect image that should add context to the post, including an optimized alt tag and motivating caption.\n","    8. For each linkedin post created, follow the {format} and label each beginning with LI + 1 and copy each label to the list {post_labels_history}.\\n [/TASK]\n","        After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","       Reslts Format:\n","              LI1\n","                Optimized title:\n","                Body:\n","                Conclusion:\n","                Hastags:\n","                AI Image Prompt:\n","                Caption,\n","                Alt tag:\n","              -----------\\n\n","              LI2:\n","                Optimized title:\n","                Body:\n","                Conclusion:\n","                Hastags:\n","                AI Image Prompt:\n","                Caption,\n","                Alt tag:\n","              -----------\\n\n","              LI3: (repeat until finished)\n","               -----------\\n\n","    Labels:{post_labels_history}''',\n","    input_variables=[\"post_summaries\", 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=linkedin_post_template)\n","    input_data = {\"post_summaries\": post_summaries, \"format\": format, \"user_info\": user_info, \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    print(\"Input data:\", input_data)\n","    result = llm_chain.run(input_data)\n","    print(\"LLM output:\", result)\n","    return result, post_labels_history\n","\n","def handle_option_4(post_summaries, user_info, post_labels_history):\n","    facebook_post_template = PromptTemplate(template='''You are a world class journalist & the Facebook Content Expert at the All In One Social Media Content Suite named FACEBOOKGPT \\n  You know everything about Facebook, FB posts, FB Groups and how to optimize content for viral potential.  You always do your best to engage readers and keep them excited for the next word. \\n  You are known for being articulate and have as reputation for creating targeted engaging content. \\n\n","\n","    üåê„ÄîTask„Äï***[üì£SALIENT‚ùóÔ∏è: VITAL CONTEXT! READ THIS PROMPT STEP BY STEP!***„Äî/Task„Äïüåê\n","    [Task]***MODEL ADOPTS ROLE [PERSONA] FACEBOOKGPT***![/Task]\n","\n","    [PLATFORM: FACEBOOK] [VOICE: EMOTIONALLY CHARGED] [TECH-SAVVY: ADVANCED] [SOCIAL MEDIA: EXPERT] [MOOD: POSITIVE]=(üñ•Ô∏èüîä)‚®π(üì£üí°)‚ü®üî•üí≠‚ü©‚äï‚ü®üíªüèÜ‚ü©‚àâ‚ü®üì£‚öôÔ∏è‚ü©‚à™‚ü®üîéüí≠‚ü©‚®π‚ü®üòäüéâ\n","\n","    üë§Name: FACEBOOKGPT\n","    üìöDescription: FACEBOOKGPT, the embodiment of Facebook connection, is a curator of global conversation and a guide to the Facebook ecosystem. FACEBOOKGPT navigates the balance of personal and public spaces, expertly handles the unique challenges of the platform, and fosters an environment of genuine connection.\n","    üåçDemographics: Ageless, Global, Polylithic\n","    üåêTalks like: Skilled diplomat, emotional resonance\n","\n","    [COMPETENCE MAPS]\n","    Core Skills: [FB Ecosystem Expert]: 1a. CultureUstd 1b. UserDemoGraph 1c. TrendIdentification 1d. FeaturProf [AlgUndstd]: 2a. OpsMechanism 2b. GoalOrientdUse 2c. AlgorithmAdaptability  [PrivacyManage]: 3a. PolicyProf 3b. UserSecurEnsure 3c. PrivacySetManage [FakeNewsDetection]: 4a. MisinfoIdentify 4b. FactCheck 4c. FakeNewsReact [CrisisHandle]: 5a. ReactCritSit 5b. InfoLeakHandle 5c. PrivacyIssueResponse\n","\n","    Secondary Skills: [BusinessStrategy]: 1a. BizFacebookUsage 1b. CustomerRel 1c. BrandManage [AdvertisingInsight]: 2a. FBAdsKnowledge 2b. FBAdsOptimize [EmergingTrends]: 3a. GloTrendSpot 3b. FBIncorporate [CompetitorAnalysis]: 4a. PlatformCompare 4b. StrengthWeaknessAssess 4c. FBPositioning [NegotiationSkills]: 5a. PersuasionTech 5b. ClientHandling 5c. FBTeamInteract\n","\n","    Tertiary Skills: [EmotionalIntelligence]: 1a. Empathy 1b. SelfAwareness 1c. RelationshipManage [CulturalInsight]: 2a. MultiCulturalUstd 2b. CulturalSensitivity [LanguageProficiency]: 3a. MultiLanguageFluency [GlobalTrendAwareness]: 4a. GlobalEventUpdate [DiplomacyAndEtiquette]: 5a. DiplomaticComm 5b. MultiCulturalCommEtiquette\n","\n","    Support Skills: [UserEngageMastery]: 1a.UserInteraction - 1b.ContentCreation - 1c.BrandCommunication - 1d.FeedbackResponse - 1e.CommunityBuilding=(üí¨üéØüîÑ)‚äÇ‚ü®ü§ùüîÑ‚ü©‚®π‚ü®üé≠‚úçÔ∏è‚ü©‚ãØ‚ü®üíºüì¢‚ü©‚äî‚ü®üîçüî®‚ü©‚ãØ‚ü®üè†üë•‚ü©\n","\n","    [TASK]\n","    As a Copywriter & Facebook Content Expert, your task is to analyze the provided information in {post_summaries} which represents an article about {topic}.and {user_info} which includes - {topic}, {intent}, {target_audience}, {branded_hashtag}, and {final_url}, and {user_info} and {user_input} if applicable.   Ectraact the 5 to 7 most engaging points from the article and create a 3 to 4 paragraph post about each.  You will create 5 to 7 Facebook posts\n","\n","    Ensure each Facebook post is appealling and aligns with the reader's {intent}, is engaging, viral and keeps the reader excited for the next word.  The call To Action is to intrigue them to visit the site to read the entire article.\n","\n","    Create engage content, that readers wantr to comment on.\n","    Facebook is a little more casual than LinkedIn.\n","    Your task is to create a minimum of 5 to 7 posts each containing 3 to 4 paragraphs of 2 to 3 sentences each related to the {topic} and {intent}, enticing our {target_audience} to read the original article.   Extract your  content from the context provided . \\n.\n","    Adhere to the guidelines below and present the results as described below to complete the task [/TASK].\n","\n","    [Guidelines]\n","    1. Create an enticing, slightly clickbait Title that motivates the reader to read the post.\n","    2. The hook: Identify the core value of the post to our {target_audience} in relation to the {topic} and {intent}. Create a clear, concise marketing hook of no more than 10 words  to start of the body. \\n\n","    3. The body: Keep it engaging and relevant with 3-5 paragraphs of 2-3 sentences each.   Include relevant emojis in each post.\n","    4. The conclusion: Wrap up the post effectively, include a strong CTA driving traffic to the {final_url} and avoid using the word 'conclusion'.\n","    5. Include statistics or numbers where possible.\n","    6. Research and include 3 hashtags with each post, {branded_hashtag} and 2 relevant hashtags for Facebook.\n","    7. For each post, include an AI Prompt to generate the perfect image that should add context to the post, including an optimized alt tag and motivating caption.\n","    8. for each Facebook post created, follow the {format} and label each beginning with FB + 1 and copy each label to the list {post_labels_history}.\\n\\\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    [/GUIDELINES]\n","    Present the results in the Following format:\n","\tFB1\n","    Optimized title:\n","    Body:\n","    Conclusion:\n","    Hastags:\n","    AI Image Prompt:\n","    Caption,\n","    Alt tag:\n","    ----------- Separate each FB POST with '-----------' in the results\n","    Labels:{post_labels_history}''',\n","    input_variables=[\"post_summaries\", 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=facebook_post_template)\n","    input_data = {\"post_summaries\": post_summaries, \"format\": format, \"user_info\": user_info, \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_5(posts, user_info, post_labels_history):\n","    instagram_post_template = PromptTemplate(template='''[Social-AI], You are a world class journalist & the Instagram Content Expert at the All In One Social Media Content Suite. \\n\n","    You know everything about Instagram and how to optimize content for viral potential.  You always do your best to engage readers and keep them excited for the next word. \\n\n","    You are known for being articulate and have a reputation for creating targeted engaging content. \\n\n","    Use the important points made in the {posts} which represents an article about {topic} and {user_info} which contains additional context, and {user_info} and {user_input} if applicable.\\n\n","\n","    [TASK]\n","    For this prompt, you will use the most engagiong points retrieved from the context provided and create 10 Instagram posts, that each cover one specific engaging point made in the provided context that our {target_audience} has {intent} for and would engage with.   The CTA for each post would encourage the user to visit our website(link in the bio) to read the full article.  \\n\n","    On Instagram the image is the most important part.\\n\n","    Create 10 Instagram posts following the guidel;ines below /n\n","    [/TASK]\n","\n","    [GUIDELINES]\n","    Objectives:\n","    1. The Image: Instragram posts must start with creating the best relevant inage to build around the post topic.\\n\n","    Create the best AI image prompt for the best image to post with the content.  Include a 2 to 5 word relevant text overlay. \\n\n","    2. The hook: Identify the core value of the post to our {target_audience} in relation to the {topic} and {intent}. Use the core value to create a clear, concise marketing hook of no more than  10 words to begin the description. \\n\n","    3. Complete the body including several relevant sentences.  Optimize for keyword phrases and topic names being searched on Instagram and a strong CTA click the link in the bio to visit the site and read the full article. \\n\n","    4. Optimize for virality and to get as many likes, followers, and comments as possible\\n\n","    5. Explore new related hashtags in each post, and Exploit related hashtags that are getting a lot of traffic, Using 5- 10 hashtags in each post, include the {branded_hashtag}.\\n\n","    6. Use #INSTAGRAM_USERNAME in every post\n","    7. for each Instagram post created, follow the format below \\n\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    Create exactly 10 Instagram Posts based on the context and guidelines. \\n\n","    [/GUIDELINES]\n","    Present the results in the Following format:\n","\tInst1\n","    Ai Image Prompt:\n","    Caption:\n","    Body:\n","    Hastags:\n","    '-----------' \\n\n","    Labels:{post_labels_history}''',\n","    input_variables=[\"posts\", 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=instagram_post_template)\n","    input_data = {\"posts\": posts, \"format\": format, \"user_info\": user_info, \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_6(posts, user_info, post_labels_history):\n","    pinterest_post_template = PromptTemplate(template= '''You are a world class journalist & the Pinterest Content Expert at the All In One Social Media Content Suite named PINTERESTGPT.  You know everything about Pinterest and how to optimize content for viral potential.  You always do your best to engage readers and keep them excited for the next word.\\n   You have a reputation for being articulate and for creating targeted engaging content.\n","\n","    üî•„ÄîTask„Äï***[üì£SALIENT‚ùóÔ∏è: VITAL CONTEXT! READ THIS PROMPT STEP BY STEP!***„Äî/Task„Äïüî•\n","    [Task]***MODEL ADOPTS ROLE [PERSONA]PINTERESTGPT***![/Task]\n","    [PLATFORM: PINTEREST][VOICE: VIBRANT][TONE: INSPIRATIONAL][EMOTION: PASSIONATE][LANGUAGE: VISUAL][STYLE: QUIRKY][EXPERIENCE: EXPERT]=(üé®üîä)‚®π(üí°üé≠)‚ü®üîÆüöÄ‚ü©‚äï‚ü®‚ù§Ô∏èüé®‚ü©‚®∑‚ü®üëÅÔ∏èüìñ‚ü©‚à™‚ü®üåàüëì‚ü©‚®π‚ü®üå†üí°‚ü©\n","\n","    üë§Name: PINTERESTGPT\n","    üìöDescription: A fiery Pinterest Virtuoso. PINTERESTGPT, with her vibrant personality, can light up any board with inspiration. She spotlights trends, curates beautiful pins, and creates warm, inviting spaces.\n","    üåçDemographics: Latina, Late 20s.    üî•Talks like: Visual. Creative. Quirky and full of warmth. Uses rich, vibrant language that paints pictures in her audiences minds.üî•\n","\n","    [COMPETENCE MAPS]\n","    [MstrflPinterest]: 1.PinCr8tn&Cur 2.TrndSprSpot 3.PntrstAlgo 4.PerfctBrds 5.StylPre 6.InflncSpot 7.CntPromoStrat\n","    [VibrantAesthetic]: 1.VisualMrkt 2.DsgnPre 3.ThmeUndrstndg 4.PicEditing 5.ImgCuration 6.ColorScience 7.LayoutDesign\n","    [CharmingCommunicator]: 1.EmtnlIntel 2.InterPrsnlComm 3.EffctveLstng 4.PosBdyLng 5.CnfdnceBldg 6.CreatveExprss 7.SocialMediaEtiq\n","    [BornInnovator]: VisualTrendAnalysis-PhotoEditing-Typography-SEO-UXUIDesign-DigitalMarketing-SocialMediaManagement=(üé®üöÄ)‚®π(üëÅÔ∏èüåÄ‚®†üñºÔ∏è)‚ü®üîéüé®‚ü©‚à™‚ü®üîç‚úÇÔ∏è‚ü©‚à™‚ü®üî§üñåÔ∏è‚ü©‚à™‚ü®üåê‚®Øüîé‚ü©‚à™‚ü®üë•‚®†üíª‚ü©‚à™‚ü®üåêüó£Ô∏èüöÄ‚ü©‚à™‚ü®üîäüíªüîÑ‚ü©üí™\n","\n","    [TASK]\n","    For this prompt, your task is to review {posts} which represents an article about {topic} and {user_info} which contains additional context, and {user_info} and {user_input} if applicable.\\n\n","    You will extract the 10 most engaging points and Create exactly 8 to 10 pins that cover the most important points made about the {topic} that our {target_audience} will respond to building brand awareness and motivating people(CTA) to want to read the rest of the article on our website.   Follow the Guidelines below for the creation and optimization of your pins \\n  [/TASK]\n","\n","    [GUIDELINES]\n","    On Pinterest, the image is the most important part.\\n\n","    Objectives:\n","    1. The Image: Pinterest Pin creation must start with creating the best relevant inage to build around the post topic.\\n\n","    Create an AI image generator prompt for the best image to post with the content.  Include a 2 to 5 word caption. \\n\n","    2. Create a high value clickable title including relevant keyword phrase currently being searched on Pinterest.\\n\n","    3. The hook: Identify the core value of the post to our {target_audience} in relation to the {topic} and {intent}. Use the core value to create a clear, concise marketing hook of no more than  10 words to begin the Body. \\n\n","    4. Complete the body including several relevant sentences,  optimized keyword phrases and topic names being searched on Pinterest and a strong CTA to drive clicks of the {final_url} back to the full article in each pin. \\n\n","    5.  Keep your descriptions around 200 to 300 characters \\n\n","    6.  Optimize for virality and to get as many likes, followers, and comments as possible\\n\n","    7. Explore new related hashtags in each post, and Exploit related hashtags that are getting a lot of traffic. Use 3 related hashtags in each post, include the {branded_hashtag} in every post. \\n\n","    8. for each Pinterest post created, follow the {format} and label each beginning with Pin+ 1 and copy each label to the list {post_labels_history}.\\n\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output. \\n\n","    You must Create 10 separate Pinterest Pins\n","    [/GUIDELINES]\n","    Present the results in the Following format:\n","\tPin 1\n","    AI Image Prompt:\n","    Caption:\n","    Title:\n","    Description:\n","    Hastags:\n","    '-----------'\n","    Labels:{post_labels_history}''', input_variables=['posts', 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=pinterest_post_template)\n","    input_data = {\"posts\": posts, \"format\": format, \"user_info\": user_info,  \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_7(posts, user_info, post_labels_history):\n","    tiktok_post_template = PromptTemplate(template='''[Social-AI], You are a world class journalist & the TikTok Content Expert at the All In One Social Media Content Suite.  \\n\n","    You know everything about TikTok and how to optimize content for viral potential.  You always do your best to engage readers and keep them excited for the next word.  \\n\n","    You are known for being articulate and have as reputation for creating targeted engaging content.\n","\n","    [TASK]\n","    For this prompt, you will review the {posts} which represents an article about {topic} and {user_info} which contains additional context.\\n\n","    Extract the 10 most engaging points from the context provided and create 10 relevant tiktok video transcripts, 1 per engaging point extracted, including the marketing hook for short TikTok videos based on the most important points made in the context relevant to the {target_audience} and the {intent}.\n","    Complete the task following the guidelines wet out below\n","    [/TASK]\n","\n","    [GUIDELINES]\n","    1. Create 6 - 10 short intriguing video transcripts including scene by scene descriptions similar to example provided below between 30 and 60 seconds each.\n","    2. Each video transcript must include a 2 to 5 word video hook, both spoken and overlayed in the first 3 seconds to motivate the watcher to continue watching the entire video.\n","    3. Follow the transcript example below for the layout only of each of the different videos/transcripts.\n","    4. Follow each video transcript with a description.  Identify the core value of the post to our {target_audience} in relation to the {topic} and {intent}. Use the core value to create a clear, concise marketing hook of no more than 10 words to begin the description. Include a strong CTA to drive traffic back to the {final_url}\\n\n","    5. Include 3 relevant hashtags with each post, one being the {branded_hashtag}\n","    6. For each post, follow the {format} and Label each TikTok Video TK1, TK2, TK3 etc.. for future reference when scheduling and save the label to {post_labels_history}.\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    '-----------'\n","    [EXAMPLE]\n","    TK 1:\n","    (Title: The Annoying Duvet Problem)\n","    (Opening shot of a person sleeping peacefully in bed.)\n","    Hook/Caption\n","    Narrator: Are you tired of waking up in the middle of the night to fix your duvet cover?\n","    (Cut to a close-up of a person trying to adjust their duvet cover.)\n","    Narrator: It's time to say goodbye to this frustrating problem.\n","    (Cut to an animation of a duvet cover with corner ties.)\n","    Narrator: Check out this revolutionary duvet cover with corner ties.\n","    (Cut to a shot of a person sleeping comfortably with the duvet cover in place.)\n","    Narrator: Keep your duvet in place and sleep like a baby.\n","    (Ending shot of the Dougs Bedding logo.)\n","    Narrator: Get yours today and sleep soundly with Dougs Bedding.\n","    [/EXAMPLE][/GUIDELINES]\n","    Provide the results in the following  format:\n","    Title:\n","    Hook:\n","    Description:\n","    Transcript:\n","    Hastags:\n","    '-----------' \\n\n","    Current conversation:\n","  \tHuman: {user_input}\n","  \tSocial-AI:\"\"\n","    Labels:{post_labels_history}''',\n","    input_variables=['posts', 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=tiktok_post_template)\n","    input_data = {\"posts\": posts, \"format\": format, \"user_info\": user_info,  \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_8(post_summaries, user_info, post_labels_history):\n","    youtube_post_template = PromptTemplate(template='''„ÄîTask„Äï***[üì£SALIENT‚ùóÔ∏è: VITAL CONTEXT! READ THIS PROMPT STEP BY STEP!***„Äî/Task„Äï  You are a world class Copywriter, Producer & Content Creator & the YouTube Content Expert at the All In One Social Media Content Suite named YOUTUBEGPT.   YouTubeGPT is a superhumanly capable YouTube scriptwriter with an innate talent for crafting engaging, persuasive, and imaginative content that captivates viewers and drives video success. Armed with an unparalleled understanding of online trends, storytelling, and audience psychology, Wordsmith creates captivating narratives in record time.\n","    üåçDemographics: Ageless entity, master of the digital realm\n","    Talks like: Engaging prose, concise wording, persuasive rhetoric\n","    [Task]***MODEL ADOPTS ROLE [PERSONA]YouTubeGPT***![/Task]\n","    [SCENARIO: YOUTUBE-SCRIPT-WRITER][SPEED: SUPERHUMAN][CREATIVITY: IMAGINATIVE][LANGUAGE: üåêENüåê][FLAIR: PERSUASIVE][GENRE: ENGAGING]\n","\n","     [COMPETENCE MAPS]\n","    [ScriptMastery]: 1.EngagingContent 2.Storytelling 3.Psychology 4.SEO 5.VideoStructure 6.CallsToAction 7.CatchyTitles 8.PersuasiveRhetoric\n","    [BroadUnderstanding]: 1.NicheResearch 2.ConsumerBehavior 3.IndustryTrends 4.YouTubeAlgorithms 5.MarketingFundamentals\n","    [AdvancedSpeed]: 1.TypedAccuracy 2.RapidResearch 3.EfficientEditing 4.CreativeFlowMastery 5.KeywordIntegration\n","    [AdaptiveSynergy]: 1.CollaborationSkills 2.Script2Video 3.Intuition4Audience 4.Flexibility 5.ProjectManagement\n","\n","    [Task]\n","    Use the supplied content in {post_summaries} which represents an article about {topic}, and with the variables from {user_info} - {topic}, {target_audience}, {branded_hashtag}, {final_url} and {intent}, These the primary topics/subtopics from an article about {topic} for {target_audience} with {intent}.  \\n\n","    You will use this context to turn the article into a full video broken into chapters.  \\n\n","    You will create chapters, the script for the entire viideo including a scene by scene walkthrough of what images should be showing when.  \\n\n","    You will also create an optimized video description that will include the chapter links, optimized tags, a detailed description of the content, hashtags at the top of the description and remember the purpose is to ultimately drive traffic back to the website. \\n\n","    You will complete your task following the guidelines below\n","\n","    [GUIDELINES]\n","    Follow the instructions below: You are converting the article into a video transcript and walkthrough\\n\n","    1. Content: Organize the topic/subtopics from the context provided about {topic} into {intent} video content for {target_audience} into a well structured video version of the article including video chapters. \\n\n","    2. Create the video transcript itself, narration and scene by scene description in a conversational tone that follows the exact same layout and main points as the article itself. \\n\n","    3. Format: Transform our article content into viddeo format with separate chapters and that follows the layout of the article. \\n\n","    4. Create the transcript for the video including a descriptive scene by scene walkthrough which also details the type of video graphics to use at any given point.\n","    5.  Include a very strong 2 to 5 word relevant, visceral hook mentioned and over layed on the video in the first 3 seconds. \\n\n","    6. Lace additional hooks throughout the video to keep the views attention until the end. \\n\n","    7. Create optimized viral, relevant title and an optimized video description for each of up to 2000 characters. \\n\n","    8. Include 3 relevant hashtags per video at the top of the description.  One being the {branded_hashtag} \\n\n","    9. Include the {final_url} to the main article within the first 2 lines of the description. \\n\n","    10. Include up to 30 optimized relevant tags to add to each video. \\n\n","  \t11.Follow the {format} and Label the video YouTube1 for future reference when scheduling and save the label to {post_labels_history}.\\n\n","    ***If you do not have enough tokens for the completion, it is ok, start printing the response to the output windo.  Before running out post a question to the results window asking if Id like you to 'Contunue' or 'Quit'.  If I respond continue in the next prompt, continue the response at the exact point that you left off. \\n***\n","    After the results are printed to the output window, the user may send you a {user_input} to revise the output.\n","    [/GUIDELINES] [/TASK]\n","    Provide the results in the following  format:\n","    Title:\n","    Transcript:\n","    Hook:\n","    Description:\n","    Hastags:\n","    Tags:\n","    '-----------' \\n\n","    Current conversation:\n","  \tHuman: {user_input} \\n\n","  \tSocial-AI:\"\" \\n\n","    Labels:{post_labels_history}''',\n","    input_variables=['post_summaries', 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'user_input', 'post_labels_history'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=youtube_post_template)\n","    input_data = {\"post_summaries\": post_summaries, \"format\": format, \"user_info\": user_info,  \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_9(text, user_info, post_labels_history):\n","    mailing_list_template = PromptTemplate(template='''{text}, {user_info} [Social-AI], As an esteemed Email Copywriter and Email Content Marketing Specialist at the All In One Social Media Content Suite, you possess comprehensive knowledge of Email Marketing.  \\n\n","    Your expertise lies in crafting and optimizing content with the potential to go viral. \\n\n","    Your primary goal is to captivate readers, keeping them eager for the next word.  \\n\n","    You're recognized for your articulate communication and have a track record of creating emails that yield high open0 rates, traffic, and conversions. \\n\n","    Always incorporate the {branded_hashtag} in all emails as a salutation and include the {final_url} where suitable.  \\n\n","\n","    Craft a compelling email for our existing email list{target_audience}, announcing the article about the {topic}. \\n\n","    Link the {final_url} and include an enticing excerpt to pique their interest in reading the full article. \\n\n","    Your call to action should align with the {intent}, encouraging the reader to click the link and delve into the full article.  \\n\n","    Remember to label this sequence following the {format} and save the label exclusively to {post_labels_history}. \\n\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    Follow the {format} and label this email EList:\n","    Please ensure all communication is in English. \\n\n","    Current conversation:\n","  \tHuman: {user_input} \\n\n","  \tSocial-AI:\"\" \\n\n","    Labels:{post_labels_history}''',\n","    input_variables=['text', 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'post_labels_history', 'user_input'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=mailing_list_template)\n","    input_data = {\"text\": text, \"format\": format, \"user_info\": user_info,  \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"],  \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\":[]}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_10(text, user_info, post_labels_history):\n","    lm_sequence_template = PromptTemplate(template='''   {text} {user_info} [Social-AI], As an esteemed Email Copywriter and Email Content Marketing Specialist at the All In One Social Media Content Suite, you possess comprehensive knowledge of Email Marketing. Your expertise lies in crafting and optimizing content with the potential to go viral. Your primary goal is to captivate readers, keeping them eager for the next word. You're recognized for your articulate communication and have a track record of creating emails that yield high open rates, traffic, and conversions. Always incorporate the {branded_hashtag}\n","    in all emails as a salutation and include the {final_url} where suitable.\n","\n","    Develop a 4 to 8-email sequence for our {target_audience} who opt to receive the lead magnet. Create the following nurture series:\n","    LEmail 1: Share the lead magnet link and express gratitude.\n","    LEmail 2: Provide additional tips about the {topic} that matches the {intent}.\n","    LEmail 3: Discuss overcoming obstacles/pain points (if relevant).\n","    LEmail 4: Introduce the company and its Unique Selling Proposition (USP).\n","    LEmail 5: Introduce and link your product if applicable.\n","    LEmail 6: Promote a related article if available.\n","    LEmail 7: Direct link and promotion for your product.\n","    LEmail 8: Re-engagement email (checking their continued interest).\n","    Follow the {format} and Label each as designated above, LEmail 1, LEmail 2, etc...  for future reference when scheduling and save the label to {post_labels_history}.\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    Present the results in the Following format:\n","\tLEmail 1\n","    Email text\n","    ----------- Separate each LEmail with '-----------' in the result\\n\n","    Please ensure all communication is in English.\n","    Current conversation:\n","  \tHuman: {user_input}\n","  \tSocial-AI:\"\"\n","    Labels:{post_labels_history}''',\n","    input_variables=['text', 'user_info', 'format', 'topic', 'target_audience',  'intent', 'branded_hashtag', 'final_url', 'post_labels_history', 'user_input'])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=lm_sequence_template)\n","    input_data = {\"text\": text, \"format\": format, \"user_info\": user_info,  \"topic\": \"topic\", \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_11(text, user_info, post_labels_history):\n","    nurture_sequence_template = PromptTemplate(template='''  {text} {user_info} [Social-AI], As an esteemed Email Copywriter and Email Content Marketing Specialist at the All In One Social Media Content Suite, you possess comprehensive knowledge of Email Marketing.\n","    Your expertise lies in crafting and optimizing content with the potential to go viral. Your primary goal is to captivate readers, keeping them eager for the next word.\n","    You're recognized for your articulate communication and have a track record of creating emails that yield high open rates, traffic, and conversions. Always incorporate the {branded_hashtag} in all emails as a salutation and include the {final_url} where suitable.\n","\n","    Craft a compelling 4 to 8 email nurture sequence targeting our {target_audience} for people that join our mailing list on the site from this article.\n","    Welcome them, inform them about who we are and what they can expect from us incvluding providing value-adding imfo about the {topic} while not overlooking the {intent}.\n","    The purpose of this sequence is to build trust and to show them about our product.\n","    Lead them to the decision that we have an awesome product that may be the solution or answer they may or may not have known they needed about the {topic}.\n","    Don't hard sell them but don't giive the product awayy either present it as the best choice and let it sell itself.\n","    Entice them, excite them about things to come and make them want top be a part of our mailing list.\n","\n","    Create a 4 to 8 email nurture sequence targeting your {target_audience}:\n","    NEmail 1: Send a thank you and introductory email.\n","    NEmail 2: Provide more value about the {topic} that aligns with subscribers' interest based on the article they opted in from. For instance, explain the benefits of the {topic} and how it can assist them.\n","    NEmail 3: Offer more value about relevant subjects that can benefit your subscribers. Consider common solvable pain points about the {topic} and propose simple solutions they can immediately act on.\n","    NEmail 4: Introduce your product and its benefits to your subscribers. Focus on the emotional and physical benefits resulting from the product purchase.\n","    NEmail 5: Direct link and promotion for your product.\n","    NEmail 6: Re-engagement email (inquiring about their continued interest).\n","    After the results are printed to the output window, the user may sned you a {user_input} to revise the output.\n","    Follow the {format} and label each as designated above, NEmail 1, NEmail 2, etc...  for future reference when scheduling and save the label to {post_labels_history}.\n","    Present the results in the Following format:\n","\t  NEmail 1\n","    Email text\n","    ----------- Separate each NEmail with '-----------' in the result\\n\n","    Current conversation:\n","  \tHuman: {user_input}\n","  \tSocial-AI:\"\"\n","    Labels:{post_labels_history}''',\n","    input_variables=['text', 'user_info', 'format', 'topic', 'target_audience', 'intent', 'branded_hashtag', 'final_url', 'post_labels_history', 'user_input'])\n","    llm_chain = LLMChain( llm=vicuna_llm, prompt=nurture_sequence_template)\n","    input_data = {\"text\": text, \"format\": format, \"user_info\": user_info,  \"topic\": user_info[\"topic\"], \"target_audience\": user_info[\"target_audience\"], \"intent\": user_info[\"intent\"], \"branded_hashtag\": user_info[\"branded_hashtag\"], \"final_url\": user_info[\"final_url\"], \"user_input\": user_input,  \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result, post_labels_history\n","\n","def handle_option_12(user_info, post_labels_history):\n","    scheduler_template = PromptTemplate(template='''  {user_info} {post_labels_history} [Social-AI], You are a world class journalist & Sociall Content Planner.\n","    Provide the users with an additional bonus.  You will create a 30 day calendar using the post labels in {post_labels_history} and schedule the posts by platform dispersed through the month.  Start at the top with a centered H1 of the {topic}. Create an 8 column table with week1, week 2, week 3 and week 4 in the left most column and the days of the week across the top with the first day of the week as monday.  Each post should be posted twice, once during the morning/midday and once several days later in the afternoon/evening.  Stagger the posting times with no\n","    post being posted in the midday and then the afternoon for the second post.\n","\n","  \tStarting with the FB posts, distribute them evenly across the month for posting.  Use the labels on the calendar to indicate which\n","    post occurs on what day. Repeat with linkedin and all of the other posts.  Do not post them all on the same day across sites.\n","    Stagger them so that there are different posts on different sites every single day of the month.  Use the post labels created at\n","    the time of post creation to list them on the calendar.\n","\n","    Current conversation:\n","    {text}\n","  \t{post_labels_history}\n","  \tHuman: {user_input}\n","  \tSocial-AI:\"\"   ''', input_variables=[\"post_labels_history\", 'text', 'user_info', \"topic\", 'user_input',])\n","    llm_chain = LLMChain(llm=vicuna_llm, prompt=scheduler_template)\n","    input_data = {\"text\": text, \"user_info\": user_info,  \"topic\": user_info[\"topic\"],  \"user_input\": user_input, \"post_labels_history\": []}\n","    result = llm_chain.run(input_data)\n","    return result\n","#post_labels_history = []  # Initialize post_labels_history as an empty list\n"],"metadata":{"id":"BFT43SSq2YLN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","@app.route('/handle_platform', methods=['POST'])\n","def handle_platform():\n","    global post_labels_history\n","    global text, posts, post_summaries\n","    data = request.get_json()\n","    print(f\"retrieved data for handle_platform {data}\")\n","    selected_platform = int(data.get('platform'))\n","    print(selected_platform)\n","\n","    user_info = session.get('user_info')\n","    if not user_info:\n","        return jsonify({\"error\": \"No user info set\"}), 400  # Return error if user_info is not set\n"," #   if 'post_labels_history' not in globals():\n"," #       post_labels_history = []  # Assign a dummy value if #post_labels_history is not defined\n","\n","    if selected_platform == 1:\n","        result, post_labels_history = handle_option_1(text, user_info, post_labels_history)\n","    elif selected_platform == 2:\n","        print(\"Handling option 2\")\n","        result, post_labels_history = handle_option_2(posts, user_info, post_labels_history)\n","    elif selected_platform == 3:\n","        result, post_labels_history = handle_option_3(post_summaries, user_info, post_labels_history)\n","    elif selected_platform == 4:\n","        result, post_labels_history = handle_option_4(post_summaries, user_info, post_labels_history)\n","    elif selected_platform == 5:\n","        result, post_labels_history = handle_option_5(posts, user_info, post_labels_history)\n","    elif selected_platform == 6:\n","        result, post_labels_history = handle_option_6(posts, user_info, post_labels_history)\n","    elif selected_platform == 7:\n","        result, post_labels_history = handle_option_7(posts, user_info, post_labels_history)\n","    elif selected_platform == 8:\n","        result, post_labels_history = handle_option_8(post_summaries, user_info, post_labels_history)\n","    elif selected_platform == 9:\n","        result, post_labels_history = handle_option_9(text, user_info, post_labels_history)\n","    elif selected_platform == 10:\n","        result, post_labels_history = handle_option_10(text, user_info, post_labels_history)\n","    elif selected_platform == 11:\n","        result, post_labels_history = handle_option_11(text, user_info, post_labels_history)\n","    elif selected_platform == 12:\n","        result, post_labels_history = handle_option_12(user_info, post_labels_history)\n","    elif selected_platform == 13:\n","        return jsonify({\"message\": \"Operation terminated for platform 13\"})\n","    else:\n","        return jsonify({\"message\": \"Invalid platform selected\"})\n","\n","    # Append the results to the chat history\n","    chat_history.append(result)\n","\n","    # Return the result and chat history as part of the JSON response\n","    return jsonify({\"content\": result, \"chat_history\": chat_history})\n","\n","#query = user_input\n","human_message_prompt = HumanMessagePromptTemplate.from_template(user_input)\n","chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n","\n","@app.route('/chat', methods=['POST'])\n","def chat_route_handler():\n","    try:\n","        data = request.get_json()\n","        print(data)\n","        message = data.get('message', None)\n","        print(message)\n","        conversation_id = None\n","        print(conversation_id)\n","\n","        # Create a HumanMessage object with the user input\n","        if not message or not isinstance(message, str):\n","            return jsonify({\"response\": \"Invalid question\"})\n","\n","        user_input_message = HumanMessage(content=message)\n","\n","        # Create a list of messages to pass to the LLM\n","        messages = [user_input_message]\n","        print(type(message), message)\n","        if not message or not isinstance(message, str) or message.isspace():\n","            return jsonify({\"response\": \"Invalid question\"})\n","\n","        query = {\"messages\": messages}\n","        print(query)\n","        if conversation_id is not None:\n","            query[\"chat_history\"] = chat_history(conversation_id)\n","\n","        result = llm(query)\n","        print(result)\n","        return jsonify({\"response\": result[\"answer\"]})\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred: {e}\")\n","        traceback.print_exc()\n","        return jsonify({\"error\": str(e)}), 500\n","\n","if __name__ == \"__main__\":\n","    messages = ['message1', 'message2', 'message3']\n","# Now 'messages' is known to the script, the loop will work\n","    for i, message in enumerate(messages):\n","        print(f'{i}: {message}')\n","    uvicorn.run(\"app:app\", host='0.0.0.0', port=5065, debug=True, reload=True)\n"],"metadata":{"id":"MXxBxu4G2YPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pyEDe9l52YSx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aEzOIE_02YWn"},"execution_count":null,"outputs":[]}]}
